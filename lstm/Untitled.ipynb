{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c02f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocess import prepare_df\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2015df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:\" + str(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42cbaf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/df_final.csv', index_col=0).drop(columns=['lat', 'lon', 'elv','date','c4','whc'])\n",
    "good_sites = pd.read_csv(\"../data/df_20210507.csv\", low_memory=False )['sitename'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41712224",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensor, df_meta, df_gpp = prepare_df(data,sites=good_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9448a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_to_train = list(range(len(df_sensor)))\n",
    "sites_to_train.remove(0)\n",
    "sites_to_test = [0]\n",
    "\n",
    "x_train = [df_sensor[i].values for i in sites_to_train]\n",
    "conditional_train = [df_meta[i].values for i in sites_to_train]\n",
    "y_train = [df_gpp[i].values.reshape(-1,1) for i in sites_to_train]\n",
    "\n",
    "x_test = [df_sensor[i].values for i in sites_to_test]\n",
    "conditional_test = [df_meta[i].values for i in sites_to_test]\n",
    "y_test = [df_gpp[i].values.reshape(-1,1) for i in sites_to_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082e28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FEATURES = len(df_sensor[0].columns) \n",
    "HIDDEN_DIM = 256\n",
    "CONDITIONAL_FEATURES = len(df_meta[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "401fc187",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(INPUT_FEATURES, CONDITIONAL_FEATURES, HIDDEN_DIM, False).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2958eeb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 (5.53s)\n",
      "Train loss: 0.1072 | R2: 0.8187\n",
      "Test loss: 0.2897 | R2: 0.7101\n",
      "Epoch: 2 (5.59s)\n",
      "Train loss: 0.1068 | R2: 0.8191\n",
      "Test loss: 0.2839 | R2: 0.7159\n",
      "Epoch: 3 (6.25s)\n",
      "Train loss: 0.1056 | R2: 0.8203\n",
      "Test loss: 0.2816 | R2: 0.7182\n",
      "Epoch: 4 (5.62s)\n",
      "Train loss: 0.1048 | R2: 0.8211\n",
      "Test loss: 0.2811 | R2: 0.7187\n",
      "Epoch: 5 (5.61s)\n",
      "Train loss: 0.1045 | R2: 0.8214\n",
      "Test loss: 0.2802 | R2: 0.7196\n",
      "Epoch: 6 (5.61s)\n",
      "Train loss: 0.1043 | R2: 0.8216\n",
      "Test loss: 0.2738 | R2: 0.7260\n",
      "Epoch: 7 (5.68s)\n",
      "Train loss: 0.1034 | R2: 0.8225\n",
      "Test loss: 0.2672 | R2: 0.7326\n",
      "Epoch: 8 (5.52s)\n",
      "Train loss: 0.1020 | R2: 0.8239\n",
      "Test loss: 0.2635 | R2: 0.7364\n",
      "Epoch: 9 (5.65s)\n",
      "Train loss: 0.1005 | R2: 0.8254\n",
      "Test loss: 0.2635 | R2: 0.7363\n",
      "Epoch: 10 (5.50s)\n",
      "Train loss: 0.1006 | R2: 0.8253\n",
      "Test loss: 0.2691 | R2: 0.7307\n",
      "Epoch: 11 (5.62s)\n",
      "Train loss: 0.1000 | R2: 0.8258\n",
      "Test loss: 0.2605 | R2: 0.7394\n",
      "Epoch: 12 (5.98s)\n",
      "Train loss: 0.0987 | R2: 0.8272\n",
      "Test loss: 0.2568 | R2: 0.7431\n",
      "Epoch: 13 (5.48s)\n",
      "Train loss: 0.0994 | R2: 0.8265\n",
      "Test loss: 0.2562 | R2: 0.7436\n",
      "Epoch: 14 (5.53s)\n",
      "Train loss: 0.0988 | R2: 0.8271\n",
      "Test loss: 0.2684 | R2: 0.7314\n",
      "Epoch: 15 (5.45s)\n",
      "Train loss: 0.0965 | R2: 0.8294\n",
      "Test loss: 0.2616 | R2: 0.7382\n",
      "Epoch: 16 (5.53s)\n",
      "Train loss: 0.0959 | R2: 0.8299\n",
      "Test loss: 0.2618 | R2: 0.7380\n",
      "Epoch: 17 (5.50s)\n",
      "Train loss: 0.0973 | R2: 0.8286\n",
      "Test loss: 0.2654 | R2: 0.7344\n",
      "Epoch: 18 (5.45s)\n",
      "Train loss: 0.0964 | R2: 0.8295\n",
      "Test loss: 0.2744 | R2: 0.7254\n",
      "Epoch: 19 (5.45s)\n",
      "Train loss: 0.0958 | R2: 0.8300\n",
      "Test loss: 0.2821 | R2: 0.7177\n",
      "Epoch: 20 (5.44s)\n",
      "Train loss: 0.0947 | R2: 0.8312\n",
      "Test loss: 0.2663 | R2: 0.7335\n",
      "Epoch: 21 (5.45s)\n",
      "Train loss: 0.0932 | R2: 0.8327\n",
      "Test loss: 0.2714 | R2: 0.7284\n",
      "Epoch: 22 (5.49s)\n",
      "Train loss: 0.0924 | R2: 0.8335\n",
      "Test loss: 0.2694 | R2: 0.7304\n",
      "Epoch: 23 (5.61s)\n",
      "Train loss: 0.0908 | R2: 0.8351\n",
      "Test loss: 0.2573 | R2: 0.7425\n",
      "Epoch: 24 (5.68s)\n",
      "Train loss: 0.0898 | R2: 0.8361\n",
      "Test loss: 0.2572 | R2: 0.7426\n",
      "Epoch: 25 (5.54s)\n",
      "Train loss: 0.0881 | R2: 0.8378\n",
      "Test loss: 0.2601 | R2: 0.7397\n",
      "Epoch: 26 (5.65s)\n",
      "Train loss: 0.0876 | R2: 0.8383\n",
      "Test loss: 0.2585 | R2: 0.7413\n",
      "Epoch: 27 (5.54s)\n",
      "Train loss: 0.0856 | R2: 0.8403\n",
      "Test loss: 0.2597 | R2: 0.7402\n",
      "Epoch: 28 (5.59s)\n",
      "Train loss: 0.0862 | R2: 0.8397\n",
      "Test loss: 0.2550 | R2: 0.7448\n",
      "Epoch: 29 (5.55s)\n",
      "Train loss: 0.0844 | R2: 0.8415\n",
      "Test loss: 0.2644 | R2: 0.7354\n",
      "Epoch: 30 (5.71s)\n",
      "Train loss: 0.0829 | R2: 0.8430\n",
      "Test loss: 0.2641 | R2: 0.7357\n",
      "Epoch: 31 (5.51s)\n",
      "Train loss: 0.0825 | R2: 0.8434\n",
      "Test loss: 0.2637 | R2: 0.7361\n",
      "Epoch: 32 (5.63s)\n",
      "Train loss: 0.0812 | R2: 0.8447\n",
      "Test loss: 0.2588 | R2: 0.7410\n",
      "Epoch: 33 (5.43s)\n",
      "Train loss: 0.0826 | R2: 0.8433\n",
      "Test loss: 0.2804 | R2: 0.7195\n",
      "Epoch: 34 (5.47s)\n",
      "Train loss: 0.0813 | R2: 0.8446\n",
      "Test loss: 0.2574 | R2: 0.7424\n",
      "Epoch: 35 (5.53s)\n",
      "Train loss: 0.0806 | R2: 0.8453\n",
      "Test loss: 0.2692 | R2: 0.7306\n",
      "Epoch: 36 (5.65s)\n",
      "Train loss: 0.0791 | R2: 0.8468\n",
      "Test loss: 0.2634 | R2: 0.7364\n",
      "Epoch: 37 (5.47s)\n",
      "Train loss: 0.0774 | R2: 0.8485\n",
      "Test loss: 0.2582 | R2: 0.7416\n",
      "Epoch: 38 (5.49s)\n",
      "Train loss: 0.0753 | R2: 0.8506\n",
      "Test loss: 0.2549 | R2: 0.7449\n",
      "Epoch: 39 (5.45s)\n",
      "Train loss: 0.0736 | R2: 0.8523\n",
      "Test loss: 0.2743 | R2: 0.7255\n",
      "Epoch: 40 (5.45s)\n",
      "Train loss: 0.0734 | R2: 0.8525\n",
      "Test loss: 0.2572 | R2: 0.7427\n",
      "Epoch: 41 (5.54s)\n",
      "Train loss: 0.0753 | R2: 0.8506\n",
      "Test loss: 0.2966 | R2: 0.7032\n",
      "Epoch: 42 (5.67s)\n",
      "Train loss: 0.0783 | R2: 0.8476\n",
      "Test loss: 0.2603 | R2: 0.7395\n",
      "Epoch: 43 (5.48s)\n",
      "Train loss: 0.0740 | R2: 0.8519\n",
      "Test loss: 0.2849 | R2: 0.7149\n",
      "Epoch: 44 (5.54s)\n",
      "Train loss: 0.0724 | R2: 0.8535\n",
      "Test loss: 0.2704 | R2: 0.7294\n",
      "Epoch: 45 (5.58s)\n",
      "Train loss: 0.0692 | R2: 0.8567\n",
      "Test loss: 0.2695 | R2: 0.7303\n",
      "Epoch: 46 (5.59s)\n",
      "Train loss: 0.0673 | R2: 0.8586\n",
      "Test loss: 0.2615 | R2: 0.7383\n",
      "Epoch: 47 (5.46s)\n",
      "Train loss: 0.0680 | R2: 0.8579\n",
      "Test loss: 0.2792 | R2: 0.7206\n",
      "Epoch: 48 (5.52s)\n",
      "Train loss: 0.0675 | R2: 0.8584\n",
      "Test loss: 0.2465 | R2: 0.7534\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d6122430b38a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = 0.0\n",
    "    train_r2 = 0.0\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    for (x, y, conditional) in zip(x_train, y_train, conditional_train):\n",
    "        x = torch.FloatTensor(x).to(DEVICE)\n",
    "        y = torch.FloatTensor(y).to(DEVICE)\n",
    "        c = torch.FloatTensor(conditional).to(DEVICE)\n",
    "\n",
    "        if x.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        y_pred = model(x, c)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.mse_loss( y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_r2 += r2_score(y_true=y.detach().cpu().numpy(), y_pred=y_pred.detach().cpu().numpy())\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "          for (x, y, conditional) in zip(x_test, y_test, conditional_test):\n",
    "            x = torch.FloatTensor(x).to(DEVICE)\n",
    "            y = torch.FloatTensor(y).to(DEVICE)\n",
    "            c = torch.FloatTensor(conditional).to(DEVICE)\n",
    "            \n",
    "\n",
    "            y_pred = model(x, c)\n",
    "\n",
    "\n",
    "            test_loss = F.mse_loss( y_pred, y)\n",
    "            test_r2 = r2_score(y_true=y.detach().cpu().numpy(), y_pred=y_pred.detach().cpu().numpy())\n",
    "    \n",
    "    end = time.time()       \n",
    "    print(f\"Epoch: {epoch+1} ({end-start:.2f}s)\")\n",
    "    print(f\"Train loss: {train_loss / len(sites_to_train):.4f} | R2: {train_r2 / len(sites_to_train):.4f}\")\n",
    "    print(f\"Test loss: {test_loss:.4f} | R2: {test_r2:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01fe55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
