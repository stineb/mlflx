---
title: "Evaluate mlflx"
author: "Beni Stocker"
date: "5/22/2021"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(patchwork)
library(ggrepel)
library(yardstick)
library(rbeni)    # get it by devtools::install_github("https://github.com/stineb/rbeni.git")
# library(ingestr)  # get it by devtools::install_github("https://github.com/geco-bern/ingestr.git")
library(cowplot)
library(jcolors)
library(ingestr)
```

## LSOCV metrics

### Read in

Obtain outputs

```{r}
df <- read_csv("data/LSTM_nocondition_results_apr22.csv")
usesites <- df$sitename |> unique()

df <- read_csv("data/DNN_nocondition_results_apr22.csv") |> 
  select(-GPP_NT_VUT_REF) |> 
  right_join(df, by = c("sitename", "date")) |> 
  rename(dnn_cond0 = dnn)

df |> analyse_modobs2("lstm_cond0", "dnn_cond0", type = "hex")
```

<!-- OLD: -->
<!-- Obtain outputs with this [link on Notion](https://www.notion.so/geco-bern/Results-2a637978b16346f98ac8c8c018ee7549#68803d0d60ca4b35b331be78c695a97c). -->
<!-- ```{r} -->
<!-- df <- read_csv("data/df_pred_denormalised.csv")  # obtained from Notion -> mlflx DSLab -> Results -> -->
<!-- usesites <- df$sitename |> unique() -->
<!-- ``` -->

Got P-model LSOCV results from `eval_pmodel/calib_results/oob_FULL/`. This includes the soil moisture stress function in model simulations. Read results here.
```{r}
filnam <- "data/df_lsocv_pmodel.rds"
if (!file.exists(filnam)){
  
  sites <- unique(df$sitename)
  
  files <- list.files("data/oob_FULL", pattern = "out_eval_leftout")
  
  get_testresults_pmodel_bysite <- function(filename){
    worked <- try(load(paste0("data/oob_FULL/", filename)))
    if (class(worked) != "try-error" & !is.na(out_eval)){
      print(paste("Reading ", filename))
      out_eval$gpp$fluxnet2015$data$ddf |>
          dplyr::select(sitename, date, pmodel = mod)
    } else {
      print(paste("Not reading ", filename))
      NULL
    }
  }
  
  df_lsocv_pmodel <- purrr::map_dfr(
    as.list(files),
    ~get_testresults_pmodel_bysite(.)
  )
  
  saveRDS(df_lsocv_pmodel, file = filnam)
    
} else {
  df_lsocv_pmodel <- readRDS("data/df_lsocv_pmodel.rds")
}
```

```{r}
## Add P-model results

# Done first, but don't remember where I got the file out_lsocv.csv from
df <- df |>
  left_join(
    read_csv("data/out_lsocv.csv") |>
      dplyr::select(sitename, date, pmodel = mod),
    by = c("sitename", "date"))

# ## Done again with data obtained as explained above
# df <- df |>
#   left_join(
#     df_lsocv_pmodel |>
#       dplyr::select(sitename, date, pmodel),
#     by = c("sitename", "date"))

# ## Add re-calculated RF results (see randomforest.Rmd)
# df_lsocv_rf <- read_rds("data/df_lsocv_rf.rds")
# df <- df |>
#   left_join(
#     df_lsocv_rf |>
#       dplyr::select(sitename, date, rf_pred = rf),
#     by = c("sitename", "date"))


# if (!exists("out_oob_FULL")){
#   load("~/eval_pmodel/calib_results/out_oob_FULL.Rdata")
# }
#
# ## for mlflx dslab course
# df <- out_oob_FULL |>
#   purrr::map("gpp") |>
#   purrr::map("fluxnet2015") |>
#   purrr::map("data") |>
#   purrr::map("ddf") |>
#   bind_rows(.id = "sitename") |>
#   select(sitename, date, pmodel = mod) |>
#   right_join(df, by = c("sitename", "date"))
```

```{r eval=FALSE}
visdat::vis_miss(df, warn_large_data = FALSE, cluster = FALSE)

df |> 
  group_by(sitename) |> 
  nest() |> 
  mutate(frac_missing = purrr::map_dbl(data, ~{1-(nrow(drop_na(., pmodel))) / nrow(.)}))
```

<!-- Get null model (gpp_null = c * fpar * SW_IN_F). This yields a constant c = 0.04381 (globally and temporally constant light use efficiency). Add gpp_null to df.  -->
<!-- ```{r} -->
<!-- df_train <- read_csv("data/ddf_combined_mlflx_20210510.csv") |>  -->
<!--   mutate(apar = fpar * SW_IN_F) -->
<!-- # df_train <- read_csv("data/ddf_combined_mlflx_20210510.csv") -->

<!-- linmod <- lm(GPP_NT_VUT_REF ~ 0 + apar, data = df_train) -->

<!-- df <- df |>  -->
<!--   left_join( -->
<!--     df_train |>  -->
<!--       dplyr::select(-GPP_NT_VUT_REF), -->
<!--     by = c("sitename", "date")) |>  -->
<!--   mutate(gpp_null = apar * linmod$coefficients[1]) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- df_oob_pmodel <- read_csv("~/mlflx/data/df_metrics_oob_stocker20gmd_fig2.csv") |>  -->
<!--   filter(site %in% usesites) -->
<!-- ``` -->

### Daily 

#### LSOCV

Evaluation as means across predictions from the LSOCV.
```{r}
## LSOCV metrics df
df_lsocv_metrics <- df |> 
  
  ## LSTM
  group_by(sitename) |> 
  nest() |> 
  mutate(out = purrr::map(data, ~rsq(., GPP_NT_VUT_REF, lstm_cond0, na_rm = TRUE))) |> 
  mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
  dplyr::select(sitename, rsq_lstm = rsq) |> 
  
  ## DNN
  left_join(
    df |> 
      group_by(sitename) |> 
      nest() |> 
      mutate(out = purrr::map(data, ~rsq(., GPP_NT_VUT_REF, dnn_cond0, na_rm = TRUE))) |> 
      mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
      dplyr::select(sitename, rsq_dnn = rsq),
    by = "sitename"
  ) |> 
  
  # ## RF
  # left_join(
  #   df |> 
  #     group_by(sitename) |> 
  #     nest() |> 
  #     mutate(out = purrr::map(data, ~rsq(., GPP_NT_VUT_REF, rf_pred, na_rm = TRUE))) |> 
  #     mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
  #     dplyr::select(sitename, rsq_rf = rsq),
  #   by = "sitename"
  # ) |> 

  ## P-MODEL
  left_join(
    df |> 
      group_by(sitename) |> 
      nest() |> 
      mutate(out = purrr::map(data, ~rsq(., GPP_NT_VUT_REF, pmodel, na_rm = TRUE))) |> 
      mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
      dplyr::select(sitename, rsq_pmodel = rsq),
    by = "sitename"
  )
  
  # ## NULL MODEL
  # left_join(
  #   df |> 
  #     group_by(sitename) |> 
  #     nest() |> 
  #     mutate(out = purrr::map(data, ~rsq(., GPP_NT_VUT_REF, gpp_null, na_rm = TRUE))) |> 
  #     mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
  #     dplyr::select(sitename, rsq_null = rsq),
  #   by = "sitename"
  # )


# LSTM
df |> 
  group_by(sitename) |> 
  nest() |> 
  mutate(out = purrr::map(data, ~rsq(., GPP_NT_VUT_REF, lstm_cond0, na_rm = TRUE))) |> 
  mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
  pull(rsq) |> 
  mean()

# DNN
df |> 
  group_by(sitename) |> 
  nest() |> 
  mutate(out = purrr::map(data, ~rsq(., GPP_NT_VUT_REF, dnn_cond0, na_rm = TRUE))) |> 
  mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
  pull(rsq) |> 
  mean()

# # RF
# df |> 
#   group_by(sitename) |> 
#   nest() |> 
#   mutate(out = purrr::map(data, ~rsq(., GPP_NT_VUT_REF, rf_pred, na_rm = TRUE))) |> 
#   mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
#   pull(rsq) |> 
#   mean(na.rm = TRUE)

# P-model
df |> 
  group_by(sitename) |> 
  nest() |> 
  mutate(out = purrr::map(data, ~rsq(., GPP_NT_VUT_REF, pmodel, na_rm = TRUE))) |> 
  mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
  pull(rsq) |> 
  mean(na.rm = TRUE)

# # NULL
# df |> 
#   group_by(sitename) |> 
#   nest() |> 
#   mutate(out = purrr::map(data, ~rsq(., GPP_NT_VUT_REF, gpp_null, na_rm = TRUE))) |> 
#   mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
#   pull(rsq) |> 
#   mean()

saveRDS(df_lsocv_metrics, file = paste0(here::here(), "/data/df_lsocv_metrics.rds"))
```

Benchmark plots
```{r}
## lstm
gg1 <- df_lsocv_metrics |> 
  ggplot(aes(rsq_pmodel, rsq_lstm, label = sitename)) +
  geom_point(color = "red") +
  xlim(0,1) + ylim(0,1) +
  geom_abline(yintercept = 0, slope = 1, linetype = "dotted") +
  theme_classic() +
  labs(x = bquote( "P-model" ~ italic(R)^2),
       y = bquote( "LSTM" ~ italic(R)^2),
       title = "LSTM") +
  geom_text_repel(min.segment.length = 0,
                segment.size = 0.2,
                width = 0.1,
                size = 2,
                seed = 42,
                box.padding = 0.5,
                color = "grey50")

## dnn
gg2 <- df_lsocv_metrics |> 
  ggplot(aes(rsq_pmodel, rsq_dnn, label = sitename)) +
  geom_point(color = "red") +
  xlim(0,1) + ylim(0,1) +
  geom_abline(yintercept = 0, slope = 1, linetype = "dotted") +
  theme_classic() +
  labs(x = bquote( "P-model" ~ italic(R)^2),
       y = bquote( "DNN" ~ italic(R)^2),
       title = "DNN") +
  geom_text_repel(min.segment.length = 0,
                segment.size = 0.2,
                width = 0.1,
                size = 2,
                seed = 42,
                box.padding = 0.5,
                color = "grey50")

# ## rf
# gg3 <- df_lsocv_metrics |> 
#   ggplot(aes(rsq_null, rsq_rf, label = sitename)) +
#   geom_point(color = "red") +
#   xlim(0,1) + ylim(0,1) +
#   geom_abline(yintercept = 0, slope = 1, linetype = "dotted") +
#   theme_classic() +
#   labs(x = bquote( "NULL model" ~ italic(R)^2),
#        y = bquote( "RF" ~ italic(R)^2),
#        title = "RF") +
#   geom_text_repel(min.segment.length = 0, seed = 42, box.padding = 0.5)

# ## for p-model
# gg3 <- df_lsocv_metrics |> 
#   ggplot(aes(rsq_null, rsq_pmodel, label = sitename)) +
#   geom_point(color = "red") +
#   xlim(0,1) + ylim(0,1) +
#   geom_abline(yintercept = 0, slope = 1, linetype = "dotted") +
#   theme_classic() +
#   labs(x = bquote( "NULL model" ~ italic(R)^2),
#        y = bquote( "P-model" ~ italic(R)^2),
#        title = "P-model") +
#   geom_text_repel(min.segment.length = 0, seed = 42, box.padding = 0.5)

plot_grid(gg1, gg2, labels = c("a", "b"))
ggsave("fig/lsocv_benchmarking.pdf", width = 10, height = 5)

gg1
ggsave(paste0(here::here(), "/fig/rsq_bysite_lstm_vs_pmodel.pdf"), width = 4, height = 4)
```

#### Relation to site-characteristics

```{r}
# load file created by nn_fluxnet2015/plot_sites_climatespace.R
sites_fluxnet2015_with_nn_fluxnet2015_info <- readRDS(paste0(here::here(), "/data/sites_fluxnet2015_with_nn_fluxnet2015_info.rds"))

tmp <- df_lsocv_metrics |> 
  left_join(
    sites_fluxnet2015_with_nn_fluxnet2015_info |> 
      select(sitename = mysitename,
             lon, lat, ai, prec, pet, aet, alpha, awc, classid, years_data),
    by = "sitename"
  ) |> 
  left_join(
    ingestr::siteinfo_fluxnet2015 |> 
      select(sitename, koeppen_code),
    by = "sitename"
  )
```

Get S_CWDX80 from Stocker et al., 2023 (DOI: 10.5281/zenodo.5515246) for each site.
```{r}
tmp <- extract_nc(
  tmp |> 
    ungroup() |> 
    dplyr::select(sitename, lon, lat), 
  "~/mct/data/cwdx80.nc") |> 
  unnest(data) |> 
  rename(cwdx80 = V1) |> 
  right_join(tmp, by = c("sitename", "lon", "lat"))
```


```{r}
# P-model - alpha
tmp |> 
  ggplot(aes(x = alpha, y = rsq_pmodel, color = classid, label = sitename)) +
  geom_point(size = 2) +
  theme_classic() +
  labs(x = "Mean annual AET/PET", y = expression(paste(italic(R)^2)), title = "P-model") +
  khroma::scale_color_discreterainbow() +
  ylim(0, 1) +
  geom_text_repel(min.segment.length = 0, seed = 42, box.padding = 0.5, color = "grey50")

ggsave(paste0(here::here(), "/fig/rsq_bysite_pmodel.pdf"), width = 5, height = 4)

# LSTM - alpha
tmp |> 
  ggplot(aes(x = alpha, y = rsq_lstm, color = classid, label = sitename)) +
  geom_point(size = 2) +
  theme_classic() +
  labs(x = "Mean annual AET/PET", y = expression(paste(italic(R)^2))) +
  khroma::scale_color_discreterainbow() +
  geom_text_repel(min.segment.length = 0,
                  width = 0.1,
                  size = 2,
                  seed = 42, 
                  box.padding = 0.5, 
                  color = "grey50")

ggsave(paste0(here::here(), "/fig/rsq_bysite_lstm_alpha.pdf"), width = 5, height = 4)

# LSTM - AI
gg1 <- tmp |> 
  ggplot(aes(x = ai, y = rsq_lstm, color = classid, label = sitename)) +
  geom_point(size = 2) +
  theme_classic() +
  labs(x = "P/PET", y = expression(paste(italic(R)^2))) +
  khroma::scale_color_discreterainbow(name = "") +
  geom_text_repel(min.segment.length = 0,
                  segment.size = 0.2,
                  width = 0.1,
                  size = 2,
                  seed = 42,
                  box.padding = 0.5,
                  color = "grey50")

ggsave(paste0(here::here(), "/fig/rsq_bysite_lstm_ai.pdf"), width = 5, height = 4)

# LSTM - CWDX80
tmp |> 
  ggplot(aes(x = cwdx80, y = rsq_lstm, color = classid, label = sitename)) +
  geom_point(size = 2) +
  theme_classic() +
  labs(x = "Maximum seasonal water deficit (mm)", y = expression(paste(italic(R)^2))) +
  khroma::scale_color_discreterainbow() +
  geom_text_repel(min.segment.length = 0,
                  width = 0.1,
                  size = 2,
                  seed = 42,
                  box.padding = 0.5,
                  color = "grey50")

ggsave(paste0(here::here(), "/fig/rsq_bysite_lstm_cwdx80.pdf"), width = 5, height = 4)

# LSTM - years data
tmp |> 
  ggplot(aes(x = years_data, y = rsq_lstm, color = classid, label = sitename)) +
  geom_point(size = 2) +
  theme_classic() +
  labs(x = "Years data", y = expression(paste(italic(R)^2))) +
  khroma::scale_color_discreterainbow() +
  geom_text_repel(min.segment.length = 0,
                  width = 0.1,
                  size = 2,
                  seed = 42, 
                  box.padding = 0.5, 
                  color = "grey50")

ggsave(paste0(here::here(), "/fig/rsq_bysite_lstm_years.pdf"), width = 5, height = 4)

# LSTM - veg type
gg2 <- tmp |> 
  ggplot(aes(x = reorder(classid, rsq_lstm), y = rsq_lstm)) +
  geom_boxplot(fill = "azure3", outlier.shape = NA) +
  geom_jitter(width = 0.25, color = "grey50") +
  theme_classic() +
  labs(x = "Vegetation type", y = expression(paste(italic(R)^2)))

# LSTM - koeppen climate
gg3 <- tmp |> 
  drop_na(koeppen_code) |> 
  filter(koeppen_code != "-") |> 
  ggplot(aes(x = reorder(koeppen_code, rsq_lstm), y = rsq_lstm)) +
  geom_boxplot(fill = "azure3", outlier.shape = NA) +
  geom_jitter(width = 0.25, color = "grey50") +
  theme_classic() +
  labs(x = "Koeppen-Geiger climate class", y = expression(paste(italic(R)^2)))

leftpanel <- cowplot::plot_grid(gg2, gg3, labels = c("b", "c"), ncol = 1)

cowplot::plot_grid(gg1, leftpanel,
                   rel_widths = c(1.2, 1), 
                   labels = c("a", ""), 
                   ncol = 2
                   )
ggsave("fig/site_eval.pdf", width = 12, height = 5)
```

Add environmental space-geographic space evaluation
```{r}
plot_map_simpl() +
  geom_point(aes(lon, lat, color = rsq_lstm), data = tmp) +
  scale_color_viridis_c()
```

```{r}
# get MAT and MAP for all sites
df_mat_map <- ingest(
  siteinfo  = tmp |> 
    select(sitename, lon, lat) |> 
    mutate(year_start = 2000, year_end = 2014),
  source    = "fluxnet",
  getvars   = list(temp = "TA_F", 
                   prec = "P_F"),
  settings  = list(getswc = FALSE),
  dir       = "~/data/FLUXNET-2015_Tier1/20191024/YY/",  # adjust this with your local path
  timescale = "y",
  verbose = TRUE
  ) |> 
  unnest(data) |> 
  group_by(sitename) |> 
  summarise(mat = mean(temp), map = mean(prec))

tmp2 <- tmp |> 
  left_join(df_mat_map, by = "sitename")

write_csv(tmp2, file = paste0(here::here(), "/data/df_sites_metainfo.csv"))

gg1 <- rbeni::plot_map_simpl() +
  geom_point(data = tmp2, 
             aes(x = lon, y = lat, fill = classid), 
             shape = 21, 
             color = "black") +
  scale_fill_brewer(palette = "Paired", name = "Vegetation type")
  # khroma::scale_fill_okabeito(name = "Vegetation type")
  # scale_colour_manual(values = myjcolors(length(unique(df_sites$classid))), name = "Vegetation type")

gg2 <- plotbiomes::whittaker_base_plot() +
  geom_point(data = tmp2, aes(x = mat, y = map/10), alpha = 0.6, size = 2) +
  theme_classic() + 
  scale_size(range = c(0, 3))

cowplot::plot_grid(gg1, gg2, ncol = 1, labels = c("a", "b"), rel_heights = c(0.6, 1))
ggsave(paste0(here::here(), "/fig/map_biomes_sites_mlflx.pdf"), width = 8, height = 8)
```

#### All data pooled

```{r}
out_lstm <- df |> 
  analyse_modobs2("lstm_cond0", "GPP_NT_VUT_REF", type = "hex", plot_legend = FALSE)
out_dnn <- df |> 
  analyse_modobs2("dnn_cond0", "GPP_NT_VUT_REF", type = "hex", plot_legend = FALSE)
out_pmodel <- df |>
  analyse_modobs2("pmodel", "GPP_NT_VUT_REF", type = "hex", plot_legend = FALSE)
# out_rf <- df |> 
#   analyse_modobs2("rf_pred", "GPP_NT_VUT_REF", type = "hex", plot_legend = FALSE)
# out_null <- df |> 
#   analyse_modobs2("gpp_null", "GPP_NT_VUT_REF", type = "hex", plot_legend = FALSE)

gg1 <- out_lstm$gg +
  labs(title = "LSTM")
gg2 <- out_dnn$gg +
  labs(title = "DNN")
gg3 <- out_pmodel$gg +
  labs(title = "P-model")
# gg3 <- out_rf$gg +
#   labs(title = "RF")
# gg4 <- out_null$gg +
#   labs(title = "NULL")

gg1 + gg2 + gg3 # + gg4
```

### Example time series

#### AU-DaP

```{r}
df |> 
  dplyr::filter(sitename == "AU-DaP" & lubridate::year(date) %in% c(2009)) |> 
  rename(lstm = lstm_cond0, dnn = dnn_cond0, pmodel = pmodel, obs = GPP_NT_VUT_REF) |> 
  pivot_longer(c(obs, lstm, dnn, pmodel),
               names_to = "model", 
               values_to = "gpp") |> 
  ggplot(aes(date, gpp, color = model)) +
  scale_color_manual(
    values = c("dnn" = "royalblue", "lstm" = "red", "obs" = "black", "pmodel" = "grey70"),
    labels = c("DNN", "LSTM", "obs.", "P-model")
    ) +
  geom_line() +
  labs(y = expression( paste("GPP (g C m"^-2, " d"^-1, ")" ) ),
       x = "Date",
       title = "AU-DaP") +
  theme_classic() +
  geom_hline(yintercept = 0, linetype = "dotted")
```

#### AU-Whr

```{r}
df |> 
  dplyr::filter(sitename == "AU-Whr" & lubridate::year(date) %in% c(2013)) |> 
  rename(lstm = lstm_cond0, dnn = dnn_cond0, pmodel = pmodel, obs = GPP_NT_VUT_REF) |> 
  pivot_longer(c(obs, lstm, dnn, pmodel),
               names_to = "model", 
               values_to = "gpp") |> 
  ggplot(aes(date, gpp, color = model)) +
  scale_color_manual(
    values = c("dnn" = "royalblue", "lstm" = "red", "obs" = "black", "pmodel" = "grey70"),
    labels = c("DNN", "LSTM", "obs.", "P-model")
    ) +
  geom_line() +
  labs(y = expression( paste("GPP (g C m"^-2, " d"^-1, ")" ) ),
       x = "Date",
       title = "AU-Whr") +
  theme_classic() +
  geom_hline(yintercept = 0, linetype = "dotted")
```

#### AU-How

```{r}
df |> 
  dplyr::filter(sitename == "AU-How" 
                & lubridate::year(date) %in% 2005:2008
                ) |> 
  rename(lstm = lstm_cond0, dnn = dnn_cond0, pmodel = pmodel, obs = GPP_NT_VUT_REF) |> 
  pivot_longer(c(obs, lstm, dnn, pmodel),
               names_to = "model", 
               values_to = "gpp") |> 
  ggplot(aes(date, gpp, color = model)) +
  scale_color_manual(
    values = c("dnn" = "royalblue", "lstm" = "red", "obs" = "black", "pmodel" = "grey70"),
    labels = c("DNN", "LSTM", "obs.", "P-model")
    ) +
  geom_line() +
  labs(y = expression( paste("GPP (g C m"^-2, " d"^-1, ")" ) ),
       x = "Date",
       title = "AU-Whr") +
  theme_classic() +
  geom_hline(yintercept = 0, linetype = "dotted")
```

### Seasonal

```{r}
df_season <- df |> 
  mutate(doy = lubridate::yday(date)) |> 
  group_by(sitename, doy) |> 
  summarise(obs = mean(GPP_NT_VUT_REF, na.rm = TRUE), 
            lstm = mean(lstm_cond0, na.rm = TRUE), 
            dnn = mean(dnn_cond0, na.rm = TRUE),
            pmodel = mean(pmodel, na.rm = TRUE)
            # rf = mean(rf_pred, na.rm = TRUE),
            # null = mean(gpp_null, na.rm = TRUE),
            # wscal = mean(wscal, na.rm = TRUE)
            )
```

<!-- Practically o missing data -->
<!-- ```{r} -->
<!-- visdat::vis_miss(df_season) -->
<!-- ``` -->

Agreement of mean seasonal cycles.
```{r}
out_lstm <- df_season |> rbeni::analyse_modobs2("lstm", "obs", type = "hex", plot_legend = FALSE)
out_dnn <- df_season |> rbeni::analyse_modobs2("dnn", "obs", type = "hex", plot_legend = FALSE)
out_pmodel <- df_season |> rbeni::analyse_modobs2("pmodel", "obs", type = "hex", plot_legend = FALSE)
# out_rf <- df_season |> rbeni::analyse_modobs2("rf", "obs", type = "hex", plot_legend = FALSE)
# out_null <- df_season |> rbeni::analyse_modobs2("null", "obs", type = "hex", plot_legend = FALSE)

gg1 <- out_lstm$gg +
  labs(title = "LSTM")
gg2 <- out_dnn$gg +
  labs(title = "DNN")
gg3 <- out_pmodel$gg +
  labs(title = "P-model")
# gg3 <- out_rf$gg +
#   labs(title = "RF")
# gg4 <- out_null$gg +
#   labs(title = "NULL")

gg1 + gg2 + gg3  # + gg4

ggsave("fig/modobs_seasonal.pdf", width = 9, height = 4)
```

Nash-Sutcliffe Efficiency (for comparison to Besnard et al., 2019: they had 0.66)
```{r}
# NSE
hydroGOF::NSE(df_season$lstm, df_season$obs, na.rm = TRUE)
hydroGOF::NSE(df_season$dnn, df_season$obs, na.rm = TRUE)
# hydroGOF::NSE(df_season$rf, df_season$obs, na.rm = TRUE)
hydroGOF::NSE(df_season$pmodel, df_season$obs, na.rm = TRUE)
# hydroGOF::NSE(df_season$null, df_season$obs, na.rm = TRUE)
```

Evaluation as means across predictions from the LSOCV.
```{r}
# LSTM
df_season |> 
  group_by(sitename) |> 
  nest() |> 
  mutate(out = purrr::map(data, ~rsq(., obs, lstm, na_rm = TRUE))) |> 
  mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
  pull(rsq) |> 
  mean()

# DNN
df_season |> 
  group_by(sitename) |> 
  nest() |> 
  mutate(out = purrr::map(data, ~rsq(., obs, dnn, na_rm = TRUE))) |> 
  mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
  pull(rsq) |> 
  mean()

# # RF
# df_season |> 
#   group_by(sitename) |> 
#   nest() |> 
#   mutate(out = purrr::map(data, ~rsq(., obs, rf, na_rm = TRUE))) |> 
#   mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
#   pull(rsq) |> 
#   mean(na.rm = TRUE)

# P-model
df_season |>
  group_by(sitename) |>
  nest() |>
  mutate(out = purrr::map(data, ~rsq(., obs, pmodel, na_rm = TRUE))) |>
  mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |>
  pull(rsq) |>
  mean(na.rm = TRUE)

# # NULL
# df_season |> 
#   group_by(sitename) |> 
#   nest() |> 
#   mutate(out = purrr::map(data, ~rsq(., obs, null, na_rm = TRUE))) |> 
#   mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
#   pull(rsq) |> 
#   mean()
```

#### By climate zone

```{r}
df_season_kgclimate <- df |> 
  left_join(
    siteinfo_fluxnet2015,
    by = "sitename"
  ) |>
  mutate(doy = lubridate::yday(date),
         northsouth = ifelse(lat>0, "North", "South")) |> 
  dplyr::filter(koeppen_code != "-") |>
  mutate(kg_code_northsouth = paste(koeppen_code, northsouth)) |> 
  group_by(kg_code_northsouth, doy) |> 
  summarise(obs = mean(GPP_NT_VUT_REF, na.rm = TRUE), 
            lstm = mean(lstm_cond0, na.rm = TRUE), 
            dnn = mean(dnn_cond0, na.rm = TRUE),
            pmodel = mean(pmodel, na.rm = TRUE))
```

Seasonal course by climate zone: LSTM works much better.
```{r}
df_season_kgclimate |> 
  pivot_longer(c(obs, lstm, dnn), names_to = "Source", values_to = "gpp") |> 
  ggplot(aes(doy, gpp, color = Source)) +
  geom_line() +
  scale_color_manual(values = c("dnn" = "royalblue", "lstm" = "red", "obs" = "black"), labels = c("DNN", "LSTM", "obs.")) +
  labs(y = expression( paste("GPP (g C m"^-2, " d"^-1, ")" ) ),
       x = "Day of year") +
  facet_wrap(~kg_code_northsouth)

ggsave("fig/meanseasonalcycle_by_climate.pdf", width = 9, height = 6)
```

LSTM performs better in different aspects, possibly due to different processes inducing different temporal dependencies in different climate zones. DNN (but not or to a lesser degree LSTM) simulates:

- Aw (tropical savannah): too early recovery of GPP in wet season.
- Cfa (temperate, no dry season, hot summer), Dfb (Cold, no dry season, warm summer), Dfc (Cold, no dry season, cold summer): too early recovery of GPP in spring
- Csa (temperate, dry summer, hot summer): underestimating peak GPP, not fast enough depression of GPP after peak season

These are exemplified by looking at individual sites.

- Aw (tropical savannah): too early recovery of GPP in wet season.

```{r}
df_season |> 
  left_join(siteinfo_fluxnet2015, by = "sitename") |> 
  dplyr::filter(koeppen_code %in% c("Aw")) |>
  pivot_longer(c(obs, lstm, dnn), names_to = "source", values_to = "gpp") |> 
  ggplot(aes(doy, gpp, color = source)) +
  geom_line() +
  scale_color_manual(values = c("dnn" = "royalblue", "lstm" = "red", "obs" = "black")) +
  facet_wrap(~sitename)
```

- Cfa (temperate, no dry season, hot summer), Dfb (Cold, no dry season, warm summer), Dfc (Cold, no dry season, cold summer): too early recovery of GPP in spring

```{r}
df_season |> 
  left_join(siteinfo_fluxnet2015, by = "sitename") |> 
  dplyr::filter(koeppen_code %in% c("Cfa", "Dfb", "Dfc")) |>
  pivot_longer(c(obs, lstm, dnn), names_to = "source", values_to = "gpp") |> 
  ggplot(aes(doy, gpp, color = source)) +
  geom_line() +
  scale_color_manual(values = c("dnn" = "royalblue", "lstm" = "red", "obs" = "black")) +
  facet_wrap(~sitename)
```
Special examples:
```{r}
siteinfo_fluxnet2015 |> 
  dplyr::filter(sitename %in% c("US-PFa", "US-UMd"))
df_season |> 
  dplyr::filter(sitename %in% c("US-PFa", "US-UMd")) |>
  pivot_longer(c(obs, lstm, dnn), names_to = "source", values_to = "gpp") |> 
  ggplot(aes(doy, gpp, color = source)) +
  geom_line() +
  scale_color_manual(values = c("dnn" = "royalblue", "lstm" = "red", "obs" = "black")) +
  facet_wrap(~sitename)
```


- Csa (temperate, dry summer, hot summer): underestimating peak GPP, not fast enough depression of GPP after peak season

```{r}
df_season |> 
  left_join(siteinfo_fluxnet2015, by = "sitename") |> 
  dplyr::filter(koeppen_code == "Csa") |>
  pivot_longer(c(obs, lstm, dnn), names_to = "source", values_to = "gpp") |> 
  ggplot(aes(doy, gpp, color = source)) +
  geom_line() +
  scale_color_manual(values = c("dnn" = "royalblue", "lstm" = "red", "obs" = "black")) +
  facet_wrap(~sitename)
```

Special examples:
```{r}
siteinfo_fluxnet2015 |> 
  dplyr::filter(sitename %in% c("FR-Pue", "US-Var"))
df_season |> 
  dplyr::filter(sitename %in% c("FR-Pue", "US-Var")) |>
  pivot_longer(c(obs, lstm, dnn), names_to = "source", values_to = "gpp") |> 
  ggplot(aes(doy, gpp, color = source)) +
  geom_line() +
  scale_color_manual(values = c("dnn" = "royalblue", "lstm" = "red", "obs" = "black")) +
  facet_wrap(~sitename)
```

#### By site

```{r}
df_season |> 
  pivot_longer(c(obs, lstm, dnn), names_to = "source", values_to = "gpp") |> 
  ggplot(aes(doy, gpp, color = source)) +
  geom_line() +
  scale_color_manual(values = c("dnn" = "royalblue", "lstm" = "red", "obs" = "black")) +
  facet_wrap(~sitename, ncol = 4)

ggsave("fig/meanseasonalcycle_by_site.pdf", width = 9, height = 20)
```

<!-- Create a table for identifying climate zones -->
<!-- ```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.6, fig.height=7, echo=FALSE} -->
<!-- ## determine which zones to plot -->
<!-- df_zones_used <- ingestr::siteinfo_fluxnet2015 |>  -->
<!--   dplyr::filter( sitename %in% usesites ) |>  -->
<!--   mutate( hemisphere = ifelse( lat>0, "north", "south" ) ) |>  -->
<!--   dplyr::select(sitename, koeppen_code, hemisphere) |>  -->
<!--   group_by( koeppen_code, hemisphere ) |> -->
<!--   nest() |> -->
<!--   mutate(nsites = purrr::map_int(data, ~nrow(.))) |>  -->

<!--   left_join( dplyr::rename( rsofun::koeppen_legend, koeppen_code = Code ), by = "koeppen_code" )|> -->
<!--   arrange( -nsites ) |>  -->
<!--   mutate(climatezone = paste(koeppen_code, hemisphere)) |>  -->
<!--   filter(!(koeppen_code=="ET")) |>  -->
<!--   ungroup() -->

<!-- df_rosetta <- tibble( -->
<!--   climatezone = c("Aw south", "BSk north", "Cfa north", "Cfb north", "Cfb south", "Csa north", "Csb north", "Dfb north", "Dfc north", "ET"), -->
<!--   label = c("Tropical savannah, dry winter, SH", "Arid steppe, cold", "Warm tem., fully humid, hot summer", "Warm tem., fully humid, warm summer", -->
<!--     "Warm tem., fully humid, warm summer, SH", "Warm tem., dry and hot summer", "Warm tem., dry and warm summer", "Cold, fully humid, warm summer",  -->
<!--     "Cold, fully humid, cold summer", "Polar tundra" )  ) -->

<!-- save(df_rosetta, file = "./data/df_rosetta.Rdata") -->

<!-- list_rosetta <- c( -->
<!--   "Aw south"  = "Tropical savannah, dry winter, SH",  -->
<!--   "BSk north" = "Arid steppe, cold",  -->
<!--   "Cfa north" = "Warm tem., fully humid, hot summer",  -->
<!--   "Cfb north" = "Warm tem., fully humid, warm summer", -->
<!--   "Cfb south" = "Warm tem., fully humid, warm summer, SH",  -->
<!--   "Csa north" = "Warm tem., dry and hot summer",  -->
<!--   "Csb north" = "Warm tem., dry and warm summer",  -->
<!--   "Dfb north" = "Cold, fully humid, warm summer",  -->
<!--   "Dfc north" = "Cold, fully humid, cold summer",  -->
<!--   "ET"        = "Polar tundra") -->

<!-- getname_climatezone <- function(myclimatezone){ -->
<!--   load("./data/df_rosetta.Rdata") -->
<!--   df_rosetta |>  -->
<!--     dplyr::filter(climatezone==myclimatezone) |>  -->
<!--     dplyr::select(label) |>  -->
<!--     unlist() -->
<!-- } -->

<!-- df_zones_used |>  -->
<!--   xtable::xtable( caption = "Caption text", auto = TRUE ) |> -->
<!--   print( hline.after=c(-1, 0), file = "./tab/table_nsites_kgclimate.tex" ) -->
<!-- ``` -->


### Daily anomalies

Anomalies from mean seasonal cycle.

```{r}
df_anom <- df |> 
  mutate(doy = lubridate::yday(date)) |> 
  rename(P_MODEL = pmodel) |> 
  left_join(df_season,
            by = c("sitename", "doy")) |> 
  mutate(obs_anom = GPP_NT_VUT_REF - obs,
         lstm_anom = lstm_cond0 - lstm,
         dnn_anom = dnn_cond0 - dnn,
         # rf_anom = rf_pred - rf,
         pmodel_anom = P_MODEL - pmodel
         # null_anom = gpp_null - null
         )

out_lstm <- df_anom |> 
  dplyr::select(mod = lstm_anom, obs = obs_anom) |> 
  analyse_modobs2("mod", "obs", type = "hex", plot_legend = FALSE)
out_dnn  <- df_anom |> 
  dplyr::select(mod = dnn_anom, obs = obs_anom) |> 
  analyse_modobs2("mod", "obs", type = "hex", plot_legend = FALSE)
out_pmodel  <- df_anom |> 
  dplyr::select(mod = pmodel_anom, obs = obs_anom) |> 
  analyse_modobs2("mod", "obs", type = "hex", plot_legend = FALSE)
# out_rf  <- df_anom |> 
#   dplyr::select(mod = rf_anom, obs = obs_anom) |> 
#   analyse_modobs2("mod", "obs", type = "hex", plot_legend = FALSE)
# out_null  <- df_anom |> 
#   dplyr::select(mod = null_anom, obs = obs_anom) |> 
#   analyse_modobs2("mod", "obs", type = "hex", plot_legend = FALSE)

gg1 <- out_lstm$gg +
  labs(title = "LSTM")
gg2 <- out_dnn$gg +
  labs(title = "DNN")
gg3 <- out_pmodel$gg +
  labs(title = "P-model")
# gg3 <- out_rf$gg +
#   labs(title = "RF")
# gg4 <- out_null$gg +
#   labs(title = "NULL")

gg1 + gg2 + gg3  # + gg4

hydroGOF::NSE(df_anom$lstm_anom, df_anom$obs_anom, na.rm = TRUE)
hydroGOF::NSE(df_anom$dnn_anom,  df_anom$obs_anom, na.rm = TRUE)
# hydroGOF::NSE(df_anom$rf_anom,  df_anom$obs_anom, na.rm = TRUE)
hydroGOF::NSE(df_anom$pmodel_anom,  df_anom$obs_anom, na.rm = TRUE)
# hydroGOF::NSE(df_anom$null_anom, df_anom$obs_anom, na.rm = TRUE)
```


Evaluation as means across predictions from the LSOCV.
```{r}
# LSTM
df_anom |> 
  group_by(sitename) |> 
  nest() |> 
  mutate(out = purrr::map(data, ~rsq(., obs_anom, lstm_anom, na_rm = TRUE))) |> 
  mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
  pull(rsq) |> 
  mean()

# DNN
df_anom |> 
  group_by(sitename) |> 
  nest() |> 
  mutate(out = purrr::map(data, ~rsq(., obs_anom, dnn_anom, na_rm = TRUE))) |> 
  mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
  pull(rsq) |> 
  mean()

# P-model
df_anom |>
  group_by(sitename) |>
  nest() |>
  mutate(out = purrr::map(data, ~rsq(., obs_anom, pmodel_anom, na_rm = TRUE))) |>
  mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |>
  pull(rsq) |>
  mean(na.rm = TRUE)

# # RF
# df_anom |> 
#   group_by(sitename) |> 
#   nest() |> 
#   mutate(out = purrr::map(data, ~rsq(., obs_anom, rf_anom, na_rm = TRUE))) |> 
#   mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
#   pull(rsq) |> 
#   mean(na.rm = TRUE)
# 
# # NULL
# df_anom |> 
#   group_by(sitename) |> 
#   nest() |> 
#   mutate(out = purrr::map(data, ~rsq(., obs_anom, null_anom, na_rm = TRUE))) |> 
#   mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
#   pull(rsq) |> 
#   mean()
```

<!-- ```{r} -->
<!-- out_msc  <- df_anom |> rbeni::analyse_modobs2("obs", "GPP_NT_VUT_REF", type = "hex") -->
<!-- out_msc$gg -->

<!-- gg1 <- df_anom |>  -->
<!--   filter(sitename == "US-Ha1") |>  -->
<!--   ggplot() + -->
<!--   geom_line(aes(date, lstm)) + -->
<!--   geom_line(aes(date, GPP_NT_VUT_REF), color = "red", alpha = 0.5) -->

<!-- gg2 <- df_anom |>  -->
<!--   filter(sitename == "US-Ha1") |>  -->
<!--   ggplot() + -->
<!--   geom_line(aes(date, obs_anom)) -->

<!-- gg3 <- df_anom |>  -->
<!--   filter(sitename == "US-Ha1") |>  -->
<!--   ggplot() + -->
<!--   geom_line(aes(date, lstm_anom)) -->

<!-- gg1 / gg2 / gg3 -->

<!-- df_anom |>  -->
<!--   ggplot(aes(obs_anom, lstm_anom)) + -->
<!--   geom_point(alpha = 0.2) -->

<!-- df_anom |>  -->
<!--   dplyr::select(mod = lstm_anom, obs = obs_anom) |>  -->
<!--   analyse_modobs2("mod", "obs", type = "hex") -->
<!-- ``` -->


### Across-site

Get site means
```{r}
df_site <- df |> 
  mutate(doy = lubridate::yday(date)) |> 
  select(sitename, GPP_NT_VUT_REF, lstm_cond0, dnn_cond0, pmodel) |> 
  drop_na() |> 
  group_by(sitename) |> 
  summarise(obs = mean(GPP_NT_VUT_REF, na.rm = TRUE), 
            lstm = mean(lstm_cond0, na.rm = TRUE), 
            dnn = mean(dnn_cond0, na.rm = TRUE),
            # rf = mean(rf_pred, na.rm = TRUE),
            pmodel = mean(pmodel, na.rm = TRUE)
            # null = mean(gpp_null, na.rm = TRUE)
            )
```

<!-- No missing data -->
<!-- ```{r} -->
<!-- visdat::vis_miss(df_site) -->
<!-- ``` -->

Agreement of site means
```{r}
out_lstm <- df_site |> 
  rbeni::analyse_modobs2("lstm", "obs")
out_dnn <- df_site |> 
  rbeni::analyse_modobs2("dnn", "obs")
# out_rf <- df_site |> 
#   rbeni::analyse_modobs2("rf", "obs")
out_pmodel <- df_site |> 
  rbeni::analyse_modobs2("pmodel", "obs")
# out_null <- df_site |> 
#   rbeni::analyse_modobs2("null", "obs")

gg1 <- out_lstm$gg +
  labs(title = "LSTM")
gg2 <- out_dnn$gg +
  labs(title = "DNN")
gg3 <- out_pmodel$gg +
  labs(title = "P-model")
# gg3 <- out_rf$gg +
#   labs(title = "RF")
# gg4 <- out_null$gg +
#   labs(title = "NULL")

gg1 + gg2 + gg3  #  + gg4
```

Nash-Sutcliffe Efficiency (for comparison to Besnard et al., 2019: they had 0.42)
```{r}
hydroGOF::NSE(df_site$lstm, df_site$obs, na.rm = TRUE)
hydroGOF::NSE(df_site$dnn, df_site$obs, na.rm = TRUE)
# hydroGOF::NSE(df_site$rf, df_site$obs, na.rm = TRUE)
hydroGOF::NSE(df_site$pmodel, df_site$obs, na.rm = TRUE)
# hydroGOF::NSE(df_site$null, df_site$obs, na.rm = TRUE)
```

R-squared
```{r}
rsq(df_site, obs, lstm)
rsq(df_site, obs, dnn)
# rsq(df_site, obs, rf)
rsq(df_site, obs, pmodel)
# rsq(ddf_site, obs, null)
```

### Annual

Get site means
```{r}
df_ann <- df |>
  rename(P_MODEL = pmodel) |> 
  mutate(doy = lubridate::yday(date)) |> 
  ## fill with mean seasonal cycle for missing observations
  left_join(df_season |> 
              rename(obs_meandoy = obs, 
                     lstm_meandoy = lstm, 
                     pmodel_meandoy = pmodel, 
                     # rf_meandoy = rf, 
                     # null_meandoy = null, 
                     dnn_meandoy = dnn
                     ), 
            by = c("sitename", "doy")) |> 
  mutate(GPP_NT_VUT_REF = ifelse(is.na(GPP_NT_VUT_REF), obs_meandoy, GPP_NT_VUT_REF)
         # rf_pred = ifelse(is.na(rf_pred), rf_meandoy, rf_pred)
         ) |> 
  mutate(year = lubridate::year(date)) |> 
  group_by(sitename, year) |> 
  summarise(obs = mean(GPP_NT_VUT_REF, na.rm = FALSE), 
            lstm = mean(lstm_cond0, na.rm = FALSE), 
            # rf = mean(rf_pred, na.rm = FALSE), 
            pmodel = mean(P_MODEL, na.rm = FALSE), 
            # null = mean(gpp_null, na.rm = FALSE), 
            dnn = mean(dnn_cond0, na.rm = FALSE)
            )
```

<!-- No missing data -->
<!-- ```{r} -->
<!-- visdat::vis_miss(df_ann) -->
<!-- ``` -->

### Annual anomalies

```{r}
df_ann <- df_ann |> 
  left_join(df_ann |> 
              group_by(sitename) |> 
              summarise(obs_mean = mean(obs, na.rm = TRUE), 
                        lstm_mean = mean(lstm, na.rm = TRUE), 
                        # null_mean = mean(null, na.rm = TRUE), 
                        # rf_mean = mean(rf, na.rm = TRUE), 
                        pmodel_mean = mean(pmodel, na.rm = TRUE), 
                        dnn_mean = mean(dnn, na.rm = TRUE)),
            by = c("sitename")) |> 
  mutate(obs_anom = obs - obs_mean,
         lstm_anom = lstm - lstm_mean,
         # null_anom = null - null_mean,
         # rf_anom = rf - rf_mean,
         pmodel_anom = pmodel - pmodel_mean,
         dnn_anom = dnn - dnn_mean)

out_lstm <- df_ann |> 
  dplyr::select(mod = lstm_anom, obs = obs_anom) |> 
  rbeni::analyse_modobs2("mod", "obs")
out_dnn <- df_ann |> 
  dplyr::select(mod = dnn_anom, obs = obs_anom) |> 
  rbeni::analyse_modobs2("mod", "obs")
# out_rf <- df_ann |> 
#   dplyr::select(mod = rf_anom, obs = obs_anom) |> 
#   rbeni::analyse_modobs2("mod", "obs")
out_pmodel <- df_ann |> 
  dplyr::select(mod = pmodel_anom, obs = obs_anom) |> 
  rbeni::analyse_modobs2("mod", "obs")
# out_null <- df_ann |> 
#   dplyr::select(mod = null_anom, obs = obs_anom) |> 
#   rbeni::analyse_modobs2("mod", "obs")

gg1 <- out_lstm$gg +
  labs(title = "LSTM")
gg2 <- out_dnn$gg +
  labs(title = "DNN")
gg3 <- out_pmodel$gg +
  labs(title = "P-model")
# gg3 <- out_rf$gg +
#   labs(title = "RF")
# gg4 <- out_null$gg +
#   labs(title = "NULL")

gg1 + gg2 + gg3 # + gg4
```

Besnard et al; 0.07
```{r}
hydroGOF::NSE(df_ann$lstm_anom, df_ann$obs_anom, na.rm = TRUE)
hydroGOF::NSE(df_ann$dnn_anom, df_ann$obs_anom, na.rm = TRUE)
hydroGOF::NSE(df_ann$pmodel_anom, df_ann$obs_anom, na.rm = TRUE)
# hydroGOF::NSE(df_ann$null_anom, df_ann$obs_anom, na.rm = TRUE)
```


Evaluation as means across predictions from the LSOCV.
```{r}
# LSTM
df_ann |> 
  group_by(sitename) |> 
  nest() |> 
  mutate(out = purrr::map(data, ~rsq(., obs_anom, lstm_anom, na_rm = TRUE))) |> 
  mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
  pull(rsq) |> 
  mean(na.rm = TRUE)

# DNN
df_ann |> 
  group_by(sitename) |> 
  nest() |> 
  mutate(out = purrr::map(data, ~rsq(., obs_anom, dnn_anom, na_rm = TRUE))) |> 
  mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
  pull(rsq) |> 
  mean(na.rm = TRUE)

# P-model
df_ann |>
  group_by(sitename) |>
  nest() |>
  mutate(out = purrr::map(data, ~rsq(., obs_anom, pmodel_anom, na_rm = TRUE))) |>
  mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |>
  pull(rsq) |>
  mean(na.rm = TRUE)

# # RF
# df_ann |> 
#   group_by(sitename) |> 
#   nest() |> 
#   mutate(out = purrr::map(data, ~rsq(., obs_anom, rf_anom, na_rm = TRUE))) |> 
#   mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
#   pull(rsq) |> 
#   mean(na.rm = TRUE)
# 
# # NULL
# df_ann |> 
#   group_by(sitename) |> 
#   nest() |> 
#   mutate(out = purrr::map(data, ~rsq(., obs_anom, null_anom, na_rm = TRUE))) |> 
#   mutate(rsq = purrr::map_dbl(out, ~pull(., .estimate))) |> 
#   pull(rsq) |> 
#   mean(na.rm = TRUE)
```

## LGOCV: Vegetation type

### Read files

```{r}
filn <- "data/bias_leave_vegtype_out_cv.rds"

if (!file.exists(filn)){
 
  ## collect predictions of model trained on GRA, and predicting on DE-Hai. 
  ## since DE-Hai is DBF, multiple models trained on GRA predicted DE-Hai, 
  ## each one with a different GRA site held out from training.
  collect_otherveg_bysite_byveg <- function(otherveg, targetveg, targetsite){
    
    all_vegtypes <- c("DBF", "ENF", "GRA", "MF")
    dfv <- tibble()
    
  }
  
  all_vegtypes <- c("DBF", "ENF", "GRA", "MF")
  dfv <- tibble()
  
  for (targetveg in all_vegtypes){

  ## get all sites of this veg type
  all_sites <- list.files(path = paste0("data/leave_", targetveg, "_out")) |> 
    str_sub(start = 1, end = 6) |> 
    unique()
  
    ## get all sites of this veg type
    all_sites <- list.files(path = paste0("data/leave_", targetveg, "_out")) |> 
      str_sub(start = 1, end = 6) |> 
      unique()
    
    ## collect predictions of model trained on remaining sites of the same veg type (targetveg)
    dfv <- dfv |> 
      bind_rows(
        read_delim(
          paste0("data/leave_", targetveg, "_out/", targetsite, "_test_bias.csv"), 
          delim = "\t", 
          col_names = c("sitename", "date", "bias")
          ) |> 
        mutate(trainedonveg = targetveg, isveg = targetveg)
        )

    ## Collect predictions of model trained on all other veg types, and predicting on target site.
    ## Multiple models trained on each other veg predicted for this target site, 
    ## each one with a different site held out from training.
    ## Average across them.
    for (otherveg in all_vegtypes[-which(all_vegtypes == targetveg)]){
      
      dfv <- dfv |>
        bind_rows( collect_otherveg_bysite_byveg(otherveg, targetveg, targetsite) )

    }
  } 
  
  write_rds(dfv, file = filn)
  
} else {
  dfv <- readRDS(filn)
}
```

### Plot

Calculate RMSEs

```{r}
rmse <- function(vec){
  sqrt( mean( (vec)^2, na.rm = TRUE) )
}

dfv_rmse <- dfv |> 
  filter(isveg == "DBF") |> 
  group_by(trainedonveg) |> 
  summarise(rmse_bias = rmse(bias)) |> 
  mutate(targetveg = "DBF") |> 
  bind_rows(
    dfv |> 
      filter(isveg == "ENF") |> 
      group_by(trainedonveg) |> 
      summarise(rmse_bias = rmse(bias)) |> 
      mutate(targetveg = "ENF")
  ) |> 
  bind_rows(
    dfv |> 
      filter(isveg == "GRA") |> 
      group_by(trainedonveg) |> 
      summarise(rmse_bias = rmse(bias)) |> 
      mutate(targetveg = "GRA")
  ) |> 
  bind_rows(
    dfv |> 
      filter(isveg == "MF") |> 
      group_by(trainedonveg) |> 
      summarise(rmse_bias = rmse(bias)) |> 
      mutate(targetveg = "MF")
  ) |> 
  select(Predict = targetveg, Trained = trainedonveg, RMSE = rmse_bias)
```

```{r}
# dfv <- readRDS("data/bias_leave_vegtype_out_cv.csv")

## add bias of the full model
dfv <- dfv |> 
  bind_rows(
    df |> 
      mutate(bias = lstm_cond0 - GPP_NT_VUT_REF) |> 
      select(sitename, date, bias) |> 
      mutate(trainedonveg = "ALL") |> 
      left_join(
        dfv |> 
          select(sitename, isveg) |> 
          unique(),
        by = "sitename"
      )
  )

## Bias on DBF sites
labs_rmse <- dfv_rmse |> 
  mutate(lab_rmse = format(RMSE, digits = 3)) |> 
  mutate(lab_rmse = paste0(Trained, ": ", lab_rmse)) |> 
  filter(Predict == "DBF") |> 
  pull(lab_rmse)

gg1 <- dfv |> 
  filter(isveg == "DBF") |> 
  ggplot(aes(x = bias, y = ..density.., color = trainedonveg)) +
  geom_density(size = 0.75) + 
  geom_vline(xintercept = 0, linetype = "dotted") +
  annotate("text", x = -14, y = 0.45, label = "RMSE, trained on", hjust = 0) +
  annotate("text", x = -14, y = seq(0.4, 0.2, length.out = 5), label = labs_rmse, colour = khroma::colour("okabe ito")(5), hjust = 0) +
  theme_classic() +
  ylim(0, 0.55) +
  labs(title = "Bias on DBF sites", 
       x = expression(paste("GPP bias (gC m"^-2, "d"^-1, ")"))) +
  khroma::scale_color_okabeito(name = "Trained on")

## Bias on GRA sites
labs_rmse <- dfv_rmse |> 
  mutate(lab_rmse = format(RMSE, digits = 3)) |> 
  mutate(lab_rmse = paste0(Trained, ": ", lab_rmse)) |> 
  filter(Predict == "GRA") |> 
  pull(lab_rmse)

gg2 <- dfv |> 
  filter(isveg == "GRA") |> 
  ggplot(aes(x = bias, y = ..density.., color = trainedonveg)) +
  geom_density(size = 0.75) + 
  geom_vline(xintercept = 0, linetype = "dotted") +
  annotate("text", x = -12, y = 0.45, label = "RMSE, trained on", hjust = 0) +
  annotate("text", x = -12, y = seq(0.4, 0.2, length.out = 5), label = labs_rmse, colour = khroma::colour("okabe ito")(5), hjust = 0) +
  theme_classic() +
  ylim(0, 0.55) +
  labs(title = "Bias on GRA sites", 
       x = expression(paste("GPP bias (gC m"^-2, "d"^-1, ")"))) +
  khroma::scale_color_okabeito(name = "Trained on")

## Bias on ENF sites
labs_rmse <- dfv_rmse |> 
  mutate(lab_rmse = format(RMSE, digits = 3)) |> 
  mutate(lab_rmse = paste0(Trained, ": ", lab_rmse)) |> 
  filter(Predict == "ENF") |> 
  pull(lab_rmse)

gg3 <- dfv |> 
  filter(isveg == "ENF") |> 
  ggplot(aes(x = bias, y = ..density.., color = trainedonveg)) +
  geom_density(size = 0.75) + 
  geom_vline(xintercept = 0, linetype = "dotted") +
  annotate("text", x = -10, y = 0.45, label = "RMSE, trained on", hjust = 0) +
  annotate("text", x = -10, y = seq(0.4, 0.2, length.out = 5), label = labs_rmse, colour = khroma::colour("okabe ito")(5), hjust = 0) +
  theme_classic() +
  ylim(0, 0.55) +
  labs(title = "Bias on ENF sites", 
       x = expression(paste("GPP bias (gC m"^-2, "d"^-1, ")"))) +
  khroma::scale_color_okabeito(name = "Trained on")

## Bias on MF sites
labs_rmse <- dfv_rmse |> 
  mutate(lab_rmse = format(RMSE, digits = 3)) |> 
  mutate(lab_rmse = paste0(Trained, ": ", lab_rmse)) |> 
  filter(Predict == "MF") |> 
  pull(lab_rmse)

gg4 <- dfv |> 
  filter(isveg == "MF") |> 
  ggplot(aes(x = bias, y = ..density.., color = trainedonveg)) +
  geom_density(size = 0.75) + 
  geom_vline(xintercept = 0, linetype = "dotted") +
  annotate("text", x = -12, y = 0.45, label = "RMSE, trained on", hjust = 0) +
  annotate("text", x = -12, y = seq(0.4, 0.2, length.out = 5), label = labs_rmse, colour = khroma::colour("okabe ito")(5), hjust = 0) +
  theme_classic() +
  ylim(0, 0.55) +
  labs(title = "Bias on MF sites", 
       x = expression(paste("GPP bias (gC m"^-2, "d"^-1, ")"))) +
  khroma::scale_color_okabeito(name = "Trained on")

plot_grid(gg1, gg2, gg3, gg4, nrow = 2, labels = c("a", "b", "c", "d"))

ggsave("fig/leave_veg_out_cv.pdf", width = 10, height = 6)
```


## LGOCV: Continent

### NEW

#### Bias on US sites
```{r}
targetcont <- "US"
trainedoncont <- "non-US"
files <- list.files(path = paste0("data/leave_", targetcont, "_out"), 
                    pattern = "_out_bias",  # taking out-of-sample predictions from multiple models, each with a different non-US site held out 
                    full.names = TRUE
                    )
heldoutsite <- str_sub(files, start = 19, end = 24)

dfc_us_trainedon_nonus <- purrr::map2_dfr(
  as.list(files),
  as.list(heldoutsite),
  ~read_delim(
    .x, 
    delim = "\t", 
    col_names = c("sitename", "date", "bias"),
    show_col_types = FALSE) |> 
    mutate(heldout = .y)
  ) |> 
  group_by(sitename, date) |> 
  summarise(bias = mean(bias)) |> 
  mutate(trainedoncont = trainedoncont, targetcont = targetcont)

# --------------------------------------------------
targetcont <- "US"
trainedoncont <- "US" # US and other non-European!!!

files <- list.files(path = "data/leave_Europe_out", 
                    pattern = "US.*_in_bias",    # taking only out-of-sample predictions for US sites where model was trained on US and other non-European sites
                    full.names = TRUE
                    )
heldoutsite <- str_sub(files, start = 23, end = 28)

dfc_us_trainedon_us <- purrr::map2_dfr(
  as.list(files),
  as.list(heldoutsite),
  ~read_delim(
    .x, 
    delim = "\t", 
    col_names = c("sitename", "date", "bias"),
    show_col_types = FALSE) |> 
    mutate(heldout = .y)
  ) |> 
  mutate(trainedoncont = trainedoncont, targetcont = targetcont)

## plot
dfc_us <- dfc_us_trainedon_us |> 
  bind_rows(dfc_us_trainedon_nonus) |> 
  bind_rows(
    df |> 
      mutate(bias = lstm_cond0 - GPP_NT_VUT_REF) |> 
      select(sitename, date, bias) |> 
      mutate(trainedoncont = "ALL", targetcont = "US", heldout = NA)
  )

tmp3 <- dfc_us |> 
  mutate(square_error = bias^2) |> 
  group_by(trainedoncont) |> 
  summarise(mean_square_error = mean(square_error, na.rm = TRUE)) |> 
  mutate(rmse = sqrt(mean_square_error), Predict = "US") |> 
  select(Predict, Trained = trainedoncont, RMSE = rmse) |> 
  mutate(lab_rmse = format(RMSE, digits = 3))
  
labs_rmse <- bind_rows(
  tmp3[1,], tmp3[3,], tmp3[2,]
  ) |> 
  mutate(lab_rmse = paste0(Trained, ": ", lab_rmse)) |> 
  pull(lab_rmse)

gg1 <- dfc_us |> 
  ggplot(aes(x = bias, y = ..density.., color = trainedoncont)) +
  geom_density(size = 0.75) + 
  geom_vline(xintercept = 0, linetype = "dotted") +
  annotate("text", x = -14, y = 0.45, label = "RMSE, trained on", hjust = 0) +
  annotate("text", x = -14, y = seq(0.4, 0.3, length.out = 3), label = labs_rmse, colour = khroma::colour("okabe ito")(3), hjust = 0) +
  theme_classic() +
  ylim(0, 0.6) +
  labs(title = "Bias on US sites", 
       x = expression(paste("GPP bias (gC m"^-2, "d"^-1, ")"))) +
  khroma::scale_color_okabeito(name = "Trained on")

gg1
```


#### Bias on Europe sites

```{r}
targetcont <- "Europe"
trainedoncont <- "non-Europe"
files <- list.files(path = paste0("data/leave_", targetcont, "_out"), 
                    pattern = "_out_bias",  # taking out-of-sample predictions from multiple models, each with a different non-US site held out 
                    full.names = TRUE
                    )
heldoutsite <- str_sub(files, start = 23, end = 28)

dfc_eu_trainedon_noneu <- purrr::map2_dfr(
  as.list(files),
  as.list(heldoutsite),
  ~read_delim(
    .x, 
    delim = "\t", 
    col_names = c("sitename", "date", "bias"),
    show_col_types = FALSE) |> 
    mutate(heldout = .y)
  ) |> 
  group_by(sitename, date) |> 
  summarise(bias = mean(bias)) |> 
  mutate(trainedoncont = trainedoncont, targetcont = targetcont)

# --------------------------------------------------
targetcont <- "Europe"
trainedoncont <- "Europe" # Europe and other non-US???

files <- list.files(path = "data/leave_US_out", 
                    pattern = "(BE|CH|CN|CZ|DE|DK|FI|FR|IT|NL|RU).*_in_bias",    # taking only out-of-sample predictions for European sites where model was trained on European and other non-US sites
                    full.names = TRUE
                    )
heldoutsite <- str_sub(files, start = 19, end = 24)

dfc_eu_trainedon_eu <- purrr::map2_dfr(
  as.list(files),
  as.list(heldoutsite),
  ~read_delim(
    .x, 
    delim = "\t", 
    col_names = c("sitename", "date", "bias"),
    show_col_types = FALSE) |> 
    mutate(heldout = .y)
  ) |> 
  mutate(trainedoncont = trainedoncont, targetcont = targetcont)

## plot
dfc_eu <- dfc_eu_trainedon_noneu |> 
  bind_rows(dfc_eu_trainedon_eu) |> 
  bind_rows(
    df |> 
      mutate(bias = lstm_cond0 - GPP_NT_VUT_REF) |> 
      select(sitename, date, bias) |> 
      mutate(trainedoncont = "ALL", targetcont = "US", heldout = NA)
  ) 

labs_rmse <- dfc_eu |> 
  mutate(square_error = bias^2) |> 
  group_by(trainedoncont) |> 
  summarise(mean_square_error = mean(square_error, na.rm = TRUE)) |> 
  mutate(rmse = sqrt(mean_square_error), Predict = "Europe") |> 
  select(Predict, Trained = trainedoncont, RMSE = rmse) |> 
  mutate(lab_rmse = format(RMSE, digits = 3)) |> 
  mutate(lab_rmse = paste0(Trained, ": ", lab_rmse)) |> 
  pull(lab_rmse)

gg2 <- dfc_eu |> 
  ggplot(aes(x = bias, y = ..density.., color = trainedoncont)) +
  geom_density(size = 0.75) + 
  geom_vline(xintercept = 0, linetype = "dotted") +
  annotate("text", x = -14, y = 0.45, label = "RMSE, trained on", hjust = 0) +
  annotate("text", x = -14, y = seq(0.4, 0.3, length.out = 3), label = labs_rmse, colour = khroma::colour("okabe ito")(3), hjust = 0) +
  ylim(0, 0.6) +
  theme_classic() +
  labs(title = "Bias on European sites", 
       x = expression(paste("GPP bias (gC m"^-2, "d"^-1, ")"))) +
  khroma::scale_color_okabeito(name = "Trained on")

gg2
```

Combine plots
```{r}
cowplot::plot_grid(gg1, gg2, labels = c("a", "b"))
ggsave("fig/leave_cont_out_cv.pdf", width = 10, height = 3)
```

Root mean square errors of continent-LGOCV.

```{r}
# predicting on European:
dfc_eu |> 
  mutate(square_error = bias^2) |> 
  group_by(trainedoncont) |> 
  summarise(mean_square_error = mean(square_error, na.rm = TRUE)) |> 
  mutate(rmse = sqrt(mean_square_error), Predict = "Europe") |> 
  select(Predict, Trained = trainedoncont, RMSE = rmse) |> 
  bind_rows(
    dfc_us |> 
      mutate(square_error = bias^2) |> 
      group_by(trainedoncont) |> 
      summarise(mean_square_error = mean(square_error, na.rm = TRUE)) |> 
      mutate(rmse = sqrt(mean_square_error), Predict = "US") |> 
      select(Predict, Trained = trainedoncont, RMSE = rmse)
  )
```



### OLD

#### Read files
```{r}
## collect predictions of model trained on 'othercont', and predicting on 
## site in 'targetcont.' 
## since this site is in 'targetcont', multiple models trained on 'othercont' 
## predicted this site, 
## each one with a different site in 'othercont' held out from training.
collect_othercont_bysite <- function(targetcont, othercont, targetsite){
  
  purrr::map_dfr(
    as.list(list.files(path = paste0("data/leave_", targetcont, "_out"), 
                       pattern = "_out_bias")),
    ~read_delim(
      paste0("data/leave_", targetcont, "_out/", .), 
      delim = "\t", 
      col_names = c("sitename", "date", "bias"),
      show_col_types = FALSE) |> 
      filter(sitename == targetsite)
    ) |> 
    group_by(sitename, date) |>
    summarise(bias = mean(bias, na.rm = TRUE), .groups = "drop_last") |>
    mutate(trainedoncont = othercont, iscont = targetcont)
  
}

all_conttypes <- c("US", "Europe")    # "Europe" contains also Australian, ...
dfc <- tibble()

for (targetcont in all_conttypes){
  
  print("//////////////////////////////")
  print(paste("targetcont:", targetcont))
  print("------------------------------")
  
  othercont <- all_conttypes[-which(all_conttypes == targetcont)]

  ## get all sites of this cont type
  all_sites <- list.files(path = paste0("data/leave_", othercont, "_out")) |> 
    str_sub(start = 1, end = 6) |> 
    unique()
  
  for (targetsite in all_sites){

    if (targetcont == "US" && str_sub(targetsite, start = 1, end = 2) == "US"){

      print(paste("targetsite:", targetsite))
      
      ## collect predictions of model trained on remaining sites 
      ## of the same cont (targetcont)
      dfc <- dfc |> 
        bind_rows(
          read_delim(
            paste0("data/leave_", othercont, "_out/", targetsite, "_in_bias.csv"), 
            delim = "\t", 
            col_names = c("sitename", "date", "bias"),
            show_col_types = FALSE
            ) |> 
          mutate(trainedoncont = targetcont, iscont = targetcont)
          )
  
      ## Collect predictions of model trained on other cont, and predicting on target site.
      ## Multiple models trained on each other cont predicted for this target site, 
      ## each one with a different site held out from training.
      ## Average across them.
      for (othercont in all_conttypes[-which(all_conttypes == targetcont)]){
  
        # print(paste("othercont:", othercont))
        
        dfc <- dfc |>
          bind_rows( collect_othercont_bysite(targetcont, othercont, targetsite) )
  
      }
      
    } ## otherwise skip

  }

}

saveRDS(dfc, file = "data/bias_leave_cont_out_cv.csv")
```

#### Plot

```{r}
rmse <- function(vec){sqrt(mean(vec^2, na.rm = TRUE))}

dfc <- readRDS("data/bias_leave_cont_out_cv.csv")

rmse_bias_trainedon_us <- dfc |> 
  filter(iscont == "US", trainedoncont == "US") |> 
  pull(bias) |> 
  rmse()

rmse_bias_trainedon_eu <- dfc |> 
  filter(iscont == "US", trainedoncont == "Europe") |> 
  pull(bias) |> 
  rmse()

## Bias on US sites
gg1 <- dfc |> 
  filter(iscont == "US") |> 
  mutate(trainedoncont = ifelse(trainedoncont == "Europe", "Non-US", trainedoncont)) |> 
  ggplot(aes(x = bias, y = ..density.., color = trainedoncont)) +
  geom_density(size = 0.75) + 
  geom_vline(xintercept = 0, linetype = "dotted") +
  theme_classic() +
  labs(title = "Bias on US sites", 
       subtitle = paste("RMSE trained on US:", 
                        format(rmse_bias_trainedon_us, digits = 3),
                        "\nRMSE trained on non-US:", 
                        format(rmse_bias_trainedon_eu, digits = 3)), 
       x = expression(paste("GPP bias (gC m"^-2, "d"^-1, ")"))) +
  khroma::scale_color_okabeito(name = "Trained on")

tmp <- df |> 
  mutate(bias = lstm_cond0 - GPP_NT_VUT_REF,
         # all other than US are "Europe" to comply with how it's done above
         cont = ifelse(str_sub(sitename, start = 1, end = 2) == "US", "US", "Europe"))

rmse_bias_us <- tmp |> 
  filter(cont == "US") |> 
  pull(bias) |> 
  rmse()
rmse_bias_eu <- tmp |> 
  filter(cont == "Europe") |> 
  pull(bias) |> 
  rmse()

gg2 <- tmp |>  
  ggplot(aes(x = bias, y = ..density.., color = trainedoncont)) +
  geom_density(size = 0.75) + 
  geom_vline(xintercept = 0, linetype = "dotted") +
  theme_classic() +
  labs(title = "Bias of LSOCV", 
       subtitle = paste("RMSE of US:", 
                        format(rmse_bias_us, digits = 3), 
                        "\nRMSE of non-US:", 
                        format(rmse_bias_eu, digits = 3)),
       x = expression(paste("GPP bias (gC m"^-2, "d"^-1, ")"))) +
  khroma::scale_color_okabeito(name = "Continent")

plot_grid(gg1, gg2, ncol = 2, labels = c("a", "b"))

ggsave("fig/leave_cont_out_cv.pdf", width = 10, height = 3)
```


## Extreme conditions

```{r}
df_extremes <- read_csv("data/dnn_extreme_condition.csv") |> 
  dplyr::select(-1) |> 
  mutate(model = "DNN") |> 
  bind_rows(
    read_csv("data/lstm_extreme_condition.csv") |> 
      dplyr::select(-1) |> 
      mutate(model = "LSTM")
  )
  
# dnn_extreme_condition$Model = "DNN"
# lstm_extreme_condition$Model = "LSTM"
# rf_extreme_condition_2$Model = "RF"
# 
# df <- rbind(dnn_extreme_condition, rf_extreme_condition_2)
# df <- rbind(df, lstm_extreme_condition)

gg1 <- ggplot(df_extremes, aes(x=model, y=lower_quantile)) +
  geom_violin(draw_quantiles =0.5) +
  geom_hline(yintercept = 0, linetype = "dotted") +
  theme_classic() + 
  ylim(-7,4) + 
  labs(title="Negative anomalies",
       x="Model", 
       y = expression(paste("Bias (gC m"^-2, "d"^-1, ")"))
       )


gg2 <- ggplot(df_extremes, aes(x=model, y=normal)) +
  geom_violin(draw_quantiles =0.5) +
  geom_hline(yintercept = 0, linetype = "dotted") +
  theme_classic() + 
  ylim(-7,4) + 
  labs(title="Normal ",
       x="Model", 
       y = expression(paste("Bias (gC m"^-2, "d"^-1, ")"))
       )


gg3 <- ggplot(df_extremes, aes(x=model, y=upper_quantile)) +
  geom_violin(draw_quantiles =0.5) +
  geom_hline(yintercept = 0, linetype = "dotted") +
  theme_classic() + 
  ylim(-7,4) + 
  labs(title="Positive anomalies",
       x="Model", 
       y = expression(paste("Bias (gC m"^-2, "d"^-1, ")"))
       )

plot_grid( 
  gg1,
  gg2,
  gg3, 
  align='v', 
  labels = c('a', 'b', 'c'), 
  nrow=1
  )
```


### Dry

Do this only within climate zones where a dryness-related bias is evident.

Hypothesis: In Csa, model bias is highest when soil moisture levels are low.

```{r}
## Bin data along deficit and make regression with upper 90% quantile
nbin <- 10
df2 <- df |>
  ungroup() |> 
  dplyr::filter(koeppen_code == "Csa") |>
  mutate(bias_lstm = lstm_cond0 - GPP_NT_VUT_REF,
         bias_dnn = dnn_cond0 - GPP_NT_VUT_REF,
         bias_null = gpp_null - GPP_NT_VUT_REF) |>
  mutate(bin = cut(wscal, breaks = seq(0.1, 0.9, by = 0.1))) |> 
  mutate(wscal_lower = as.numeric( sub("\\((.+),.*", "\\1", bin)),
         wscal_upper = as.numeric( sub("[^,]*,([^]]*)\\]", "\\1", bin) )
         ) |> 
  mutate(wscal_mid = (wscal_lower + wscal_upper)/2) |> 
  mutate(wscal_mid = as.factor(wscal_mid)) |> 
  dplyr::select(-bin, -wscal_lower, -wscal_upper)
  
df2 |> 
  ggplot(aes(wscal_mid, bias_lstm)) +
  geom_violin()
```

### Cold stress

Do this only for climate zones where a (early season) temperature-related bias is evident.
Consider min temp of the preceding month.

Hypothesis: In Cfa (temperate, no dry season, hot summer), Dfb (Cold, no dry season, warm summer), Dfc (Cold, no dry season, cold summer), model bias is highest when minimum temperature of preceeding month was lowest (keeping only growing season data)

```{r}
df_season |> 
  left_join(ingestr::siteinfo_fluxnet2015, by = "sitename") |> 
  dplyr::filter(koeppen_code %in% c("Cfa", "Dfb", "Dfc")) |>
  pivot_longer(c(obs, lstm, dnn), names_to = "source", values_to = "gpp") |> 
  ggplot(aes(doy, gpp, color = source)) +
  geom_line() +
  scale_color_manual(values = c("dnn" = "royalblue", "lstm" = "red", "obs" = "black")) +
  facet_wrap(~sitename)
```


<!-- ## Comparison to physical model -->

<!-- Load out-of-bag (OOB) cross validation results from Stocker et al. (2020) (file `df_metrics_oob_stocker20gmd_fig2.csv`), and from the LSTM. -->
<!-- ```{r cars} -->
<!-- usesites <- df$sitename |> unique() -->

<!-- df_oob_pmodel <- read_csv("~/mlflx/data/df_metrics_oob_stocker20gmd_fig2.csv") |>  -->
<!--   filter(site %in% usesites) -->

<!-- df_oob_pmodel -->

<!-- df_oob_pmodel <- read_csv("~/mlflx/data/lstm_100e_r2.csv") |> -->
<!--   rename(rsq = R2, site = Site) -->
<!-- ``` -->

<!-- Plot histograms of R-squared of OOB-CV for the two. -->
<!-- ```{r pressure, echo=FALSE} -->
<!-- gg1 <- df_oob_pmodel |>  -->
<!--   ggplot() + -->
<!--   geom_histogram(aes(x = rsq, y = ..count..), -->
<!--     color = "black", alpha = 0.3, binwidth = 0.05,  -->
<!--     position="identity") + -->
<!--   theme_classic() + -->
<!--   labs(x = bquote(italic(R)^2), y = "Count") + -->
<!--   xlim(0.2, 1) -->

<!-- gg2 <- df_oob_mlflx |>  -->
<!--   ggplot() + -->
<!--   geom_histogram(aes(x = rsq, y = ..count..), -->
<!--     color = "black", alpha = 0.3, binwidth = 0.05,  -->
<!--     position="identity") + -->
<!--   theme_classic() + -->
<!--   labs(x = bquote(italic(R)^2), y = "Count") + -->
<!--   xlim(0.2, 1) -->

<!-- gg1 / gg2 -->
<!-- ``` -->

<!-- This is the plot I sent through Slack. -->
<!-- ```{r pressure, echo=FALSE} -->
<!-- df <- df_oob_pmodel |>  -->
<!--   rename(rsq_pmodel = rsq) |>  -->
<!--   full_join(df_oob_mlflx |> rename(rsq_ml = rsq), by = "site") -->

<!-- df |>  -->
<!--   ggplot(aes(x = rsq_pmodel, y = rsq_ml, label = site)) + -->
<!--   geom_point(size = 2, color = "red") + -->
<!--   theme_classic() + -->
<!--   geom_abline(slope = 1, intercept = 0, linetype = "dotted") + -->
<!--   xlim(0, 1) + ylim(0, 1) + -->
<!--   geom_text_repel(min.segment.length = 0, seed = 42, box.padding = 0.5) + -->
<!--   labs(x = bquote("Physical model" ~ italic(R)^2), y = bquote("ML" ~ italic(R)^2)) -->

<!-- ggsave("~/mlflx/fig/rsq_oob_comparison.pdf", width = 5, height = 4) -->
<!-- ``` -->


<!-- This is something else I did for myself (beni). -->
<!-- ```{r} -->
<!-- # df_mlflx <- read_csv("~/mlflx/data/ddf_combined_mlflx_20210510.csv") -->
<!-- #  -->
<!-- # df_mlflx |>  -->
<!-- #   dplyr::filter(classid == "DBF") |>  -->
<!-- #   pull(sitename) |>  -->
<!-- #   unique() -->
<!-- #  -->
<!-- # df_mlflx |>  -->
<!-- #   dplyr::filter(sitename == "US-Var") |>  -->
<!-- #   slice(2000:3600) |>  -->
<!-- #   ggplot(aes(x = date)) + -->
<!-- #   geom_line(aes(y = GPP_NT_VUT_REF)) -->
<!-- #  -->
<!-- # df_mlflx |>  -->
<!-- #   dplyr::filter(sitename == "US-Var") |>  -->
<!-- #   slice(2000:3600) |>  -->
<!-- #   ggplot(aes(x = date)) + -->
<!-- #   geom_line(aes(y = fpar)) -->

<!-- df_metrics <- df_mlflx |>  -->
<!--   dplyr::filter(sitename == "FR-Pue") |>  -->
<!--   yardstick::metrics("fpar", "GPP_NT_VUT_REF") |>  -->
<!--   mutate(sitename = "FR-Pue") |>  -->
<!--   bind_rows( -->
<!--     df_mlflx |>  -->
<!--       dplyr::filter(sitename == "CH-Lae") |>  -->
<!--       yardstick::metrics("fpar", "GPP_NT_VUT_REF") |>  -->
<!--       mutate(sitename = "CH-Lae") -->
<!--   ) |>  -->
<!--   dplyr::filter(.metric == "rsq") |>  -->
<!--   mutate(.estimate = format(.estimate, digits = 2)) -->

<!-- gg1 <- df_mlflx |>  -->
<!--   dplyr::filter(sitename == "CH-Lae") |>  -->
<!--   ggplot(aes(y = GPP_NT_VUT_REF, x = fpar)) + -->
<!--   geom_hex(bins = 30) + -->
<!--   scale_fill_gradientn( -->
<!--     colours = colorRampPalette( c("gray65", "navy", "red", "yellow"))(5) -->
<!--     # , trans = "log", breaks = c(1, 10) -->
<!--     ) + -->
<!--   theme_classic() + -->
<!--   labs( -->
<!--     title = "Deciduous forest: CH-Lae",  -->
<!--     subtitle = bquote( italic(R)^2 == .(df_metrics |> dplyr::filter( sitename == "CH-Lae") |> pull(.estimate))), -->
<!--     y = expression(paste("GPP (gC m"^-2, "s"^-1, ")")), x = "MODIS EVI") + -->
<!--   theme_classic() +  -->
<!--   geom_smooth(method='lm', color="red", size=0.5, se=FALSE) -->

<!-- gg2 <- df_mlflx |>  -->
<!--   dplyr::filter(sitename == "FR-Pue") |>  -->
<!--   ggplot(aes(y = GPP_NT_VUT_REF, x = fpar)) + -->
<!--   geom_hex(bins = 30) + -->
<!--   scale_fill_gradientn( -->
<!--     colours = colorRampPalette( c("gray65", "navy", "red", "yellow"))(5) -->
<!--     # , trans = "log", breaks = c(1, 10) -->
<!--     ) + -->
<!--   theme_classic() + -->
<!--   labs( -->
<!--     title = "Evergreen forest: FR-Pue",  -->
<!--     subtitle = bquote( italic(R)^2 == .(df_metrics |> dplyr::filter( sitename == "FR-Pue") |> pull(.estimate))), -->
<!--     y = expression(paste("GPP (gC m"^-2, "s"^-1, ")")), x = "MODIS EVI") + -->
<!--   theme_classic()  -->

<!-- gg1 + gg2 -->
<!-- ggsave("~/polybox/fig/gpp_evi.pdf", width = 8, height = 4) -->
<!-- ``` -->
